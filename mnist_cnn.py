# -*- coding: utf-8 -*-
"""MNIST CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ObmkCCtWMPv_hpX8sxyXWFVI5se52SPs
"""

import torch
import torch.nn as nn #sinir ağı katmanlarını oluşturmak için kullanılan modül
import torch.optim as optim #optimizasyon algoritmalarını içerir
import torch.nn.functional as F
from torchvision import datasets, transforms #veri setine veri dönüştürmelerini ekler
from torch.utils.data import DataLoader #veriyi mini-batchler halinde yükler

transform = transforms.ToTensor() #Verileri PyTorch tensörlerine dönüştürür

train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)
test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)

train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

class CNN(nn.Module):
  def __init__(self):
    super(CNN, self).__init__()
    self.conv1 = nn.Conv2d(1, 16,3) #1 giriş kanalı, 16 filtre, 3x3 çekirdek
    self.conv2 = nn.Conv2d(16, 32, 3) #16 giriş kanalı, 32 filtre, 3x3 çekirdek
    self.fc1 = nn.Linear(32*12*12, 64) #Fully connected layer
    self.fc2 = nn.Linear(64,10) #Son katman , 10 sınıf

  def forward(self,x):
    x = torch.relu(self.conv1(x))
    x = torch.relu(self.conv2(x))
    x = torch.max_pool2d(x,2)
    x = x.view(-1, 32*12*12)
    x = torch.relu(self.fc1(x))
    x = self.fc2(x)
    return x

model = CNN()
optimizer = optim.Adam(model.parameters(), lr=0.001)
criterion = nn.CrossEntropyLoss()

def train(model, train_loader, optimizer, criterion):
  model.train()
  for data, target in train_loader:
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output, target)
    loss.backward()
    optimizer.step()

def test(model, test_loader, criterion):
  model.eval()
  test_loss = 0
  correct = 0
  with torch.no_grad():
    for data, target in test_loader:
      output = model(data)
      test_loss += criterion(output, target).item()
      pred = output.argmax(dim=1, keepdim=True)
      correct += pred.eq(target.view_as(pred)).sum().item()
  print(f'Accuracy: {correct/ len(test_loader.dataset): .4f}')


for epoch in range(1, 6):
  train(model, train_loader, optimizer, criterion)
  test(model, test_loader, criterion)